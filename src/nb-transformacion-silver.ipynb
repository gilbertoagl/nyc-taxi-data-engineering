{"cells":[{"cell_type":"code","source":["from pyspark.sql.functions import col, year, month, to_date, when, count, lit, current_timestamp, md5, concat_ws, input_file_name\n","from pyspark.sql.types import *\n","from notebookutils import mssparkutils\n","\n","# Variables de parametros\n","TAXI_TYPE = \"yellow\"\n","DATE_ID = \"2023-01\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"93209aba-45ba-4fad-a26a-287f0d6beb54"},{"cell_type":"code","source":["from delta.tables import DeltaTable\n","\n","# Rutas\n","SOURCE_PATH = f\"Files/raw_Data/{TAXI_TYPE}_Taxi/{TAXI_TYPE}_tripdata_{DATE_ID}.parquet\"\n","TABLE_NAME = f\"silver_{TAXI_TYPE}_taxi\"\n","\n","print(f\"Procesando: {TAXI_TYPE} - {DATE_ID}\")\n","\n","# Carga de Bronze\n","try:\n","    df_bronze = spark.read.parquet(SOURCE_PATH)\n","except:\n","    mssparkutils.notebook.exit(f\"No se encontroel archivo en: {SOURCE_PATH}\")\n","\n","# Normalizar nombres de columnas\n","if \"tpep_pickup_datetime\" in df_bronze.columns:\n","    df_bronze = df_bronze.withColumnRenamed(\"tpep_pickup_datetime\", \"pickup_time\") \\\n","                         .withColumnRenamed(\"tpep_dropoff_datetime\", \"dropoff_time\")\n","elif \"lpep_pickup_datetime\" in df_bronze.columns:\n","    df_bronze = df_bronze.withColumnRenamed(\"lpep_pickup_datetime\", \"pickup_time\") \\\n","                         .withColumnRenamed(\"lpep_dropoff_datetime\", \"dropoff_time\")\n","\n","# Transformación y Selección\n","df_silver = df_bronze.select(\n","    col(\"pickup_time\").cast(\"timestamp\"),\n","    col(\"dropoff_time\").cast(\"timestamp\"),\n","    col(\"passenger_count\").cast(\"int\"),\n","    col(\"trip_distance\").cast(\"double\"),\n","    col(\"PULocationID\").cast(\"int\").alias(\"pickup_zone_id\"),\n","    col(\"DOLocationID\").cast(\"int\").alias(\"dropoff_zone_id\"),\n","    col(\"payment_type\").cast(\"int\"),\n","    col(\"fare_amount\").cast(\"double\"),\n","    col(\"tip_amount\").cast(\"double\"),\n","    col(\"total_amount\").cast(\"double\"),\n","    lit(TAXI_TYPE).alias(\"taxi_type\"), \n","    lit(\"batch_pipeline\").alias(\"ingestion_source\"),\n","    input_file_name().alias(\"source_file\"),\n","    current_timestamp().alias(\"processed_at\")\n",")\n","\n","# Data Quality y Generación de ID unico\n","df_final = df_silver.filter(\n","    (col(\"trip_distance\") > 0) & \n","    (col(\"total_amount\") > 0) & \n","    (col(\"pickup_time\") < col(\"dropoff_time\"))\n",").withColumn(\n","    \"trip_id\", \n","    md5(concat_ws(\"-\", \n","        col(\"taxi_type\"), \n","        col(\"pickup_time\"), \n","        col(\"dropoff_time\"), \n","        col(\"pickup_zone_id\"), \n","        col(\"dropoff_zone_id\"),\n","        col(\"trip_distance\"),\n","        col(\"total_amount\")\n","    ))\n",").withColumn(\"year\", year(col(\"pickup_time\"))) \\\n"," .withColumn(\"month\", month(col(\"pickup_time\"))) \\\n"," .dropDuplicates([\"trip_id\"]) # <--- garantía de no duplicados después de los filtros\n","\n","# GUARDADO CON MERGE\n","if spark.catalog.tableExists(TABLE_NAME):\n","    print(f\"La tabla {TABLE_NAME} ya existe. Aplicando MERGE...\")\n","    dt = DeltaTable.forName(spark, TABLE_NAME)\n","    \n","    dt.alias(\"target\").merge(\n","        df_final.alias(\"updates\"),\n","        \"target.trip_id = updates.trip_id\"\n","    ).whenMatchedUpdateAll() \\\n","     .whenNotMatchedInsertAll() \\\n","     .execute()\n","else:\n","    print(f\"La tabla {TABLE_NAME} no existe. Creándola...\")\n","    df_final.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(TABLE_NAME)\n","\n","print(f\"Finalizado con éxito: {TABLE_NAME}\")\n","mssparkutils.notebook.exit(\"OK\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":[]},"id":"60a1780b-6abb-4f45-b0c1-407a72386474"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"es"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"82077e88-b0be-4cb9-b3ff-59f337d2d701","known_lakehouses":[{"id":"82077e88-b0be-4cb9-b3ff-59f337d2d701"}],"default_lakehouse_name":"lh_nyc_taxi","default_lakehouse_workspace_id":"c9502be8-dc84-42e3-991f-9d3da5ba2ee3"}}},"nbformat":4,"nbformat_minor":5}